{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression #羅吉斯迴歸\n",
    "from sklearn.ensemble import RandomForestClassifier #隨機森林\n",
    "from sklearn.naive_bayes import MultinomialNB  # 朴素貝葉斯\n",
    "from sklearn.ensemble import GradientBoostingClassifier #梯度提升樹（Gradient Boosting Tree）\n",
    "from sklearn.svm import SVC  # 支持向量機 \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 讀取資料集\n",
    "data = pd.read_excel('job_predict.xlsx')  \n",
    "# 2. 切分特徵和標籤\n",
    "features = data['職缺名稱']  # 工作名稱在'工作名稱'欄位中\n",
    "labels = data['擅長工具']  # 擅長技能在'擅長技能'欄位中\n",
    "# 3. 特徵轉換\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), token_pattern=None)  # 使用逗號分隔\n",
    "features = vectorizer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"這一段程式碼是為了建立一個 CountVectorizer 物件，用於將文本特徵轉換為數值特徵。CountVectorizer 是一個在sklearn中提供的文本特徵提取工具，它可以將文本轉換為詞彙的計數向量。\\n\\n在這段程式碼中，我們使用了自定義的分詞器 lambda x: x.split(',')，該分詞器將文本按逗號進行分割，以獲得單獨的詞彙。這意味著如果文本中的單詞是以逗號分隔的，則它們將被視為不同的詞彙。\\n\\n另外，token_pattern=None 的設置是為了避免預設的正則表達式對詞彙進行過濾。這樣做可以確保所有的詞彙都被保留下來，而不受預設的正則表達式的限制。\\n\\n總之，這段程式碼設定了一個 CountVectorizer 物件，使用逗號作為分隔符，並且不對詞彙進行過濾，從而實現了將文本特徵轉換為計數向量的功能。\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','), token_pattern=None)  # 使用逗號分隔\n",
    "\n",
    "'''這一段程式碼是為了建立一個 CountVectorizer 物件，用於將文本特徵轉換為數值特徵。CountVectorizer 是一個在sklearn中提供的文本特徵提取工具，它可以將文本轉換為詞彙的計數向量。\n",
    "\n",
    "在這段程式碼中，我們使用了自定義的分詞器 lambda x: x.split(',')，該分詞器將文本按逗號進行分割，以獲得單獨的詞彙。這意味著如果文本中的單詞是以逗號分隔的，則它們將被視為不同的詞彙。\n",
    "\n",
    "另外，token_pattern=None 的設置是為了避免預設的正則表達式對詞彙進行過濾。這樣做可以確保所有的詞彙都被保留下來，而不受預設的正則表達式的限制。\n",
    "\n",
    "總之，這段程式碼設定了一個 CountVectorizer 物件，使用逗號作為分隔符，並且不對詞彙進行過濾，從而實現了將文本特徵轉換為計數向量的功能。'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = vectorizer.fit_transform(features)\n",
    "'''這一段程式碼是用來將原始的文本特徵 features 轉換成計數向量。具體來說，fit_transform() 方法結合了兩個步驟：fit 和 transform。\n",
    "\n",
    "首先，使用 vectorizer.fit(features) 方法來擬合（fit） CountVectorizer 物件，它會根據提供的文本特徵 features 學習詞彙表（vocabulary）。這個詞彙表是由文本中出現的所有詞彙所構成的集合。\n",
    "\n",
    "接著，使用 vectorizer.transform(features) 方法來將文本特徵 features 轉換成計數向量表示。該方法將每個文本特徵表示為一個向量，其中向量的每個元素表示該詞彙在該文本中出現的次數。\n",
    "\n",
    "最終，features 變數將被覆蓋為轉換後的計數向量。這樣，原始的文本特徵將被轉換為數值特徵，以便進行後續的機器學習模型訓練和預測。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 切分訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "'''這一段程式碼是用來將資料集分割成訓練集和測試集，以便在機器學習模型中進行訓練和評估。\n",
    "\n",
    "train_test_split() 函式是 scikit-learn 中的一個工具，它可以將資料集（這裡是 features 和 labels）切分成訓練集和測試集。具體來說，這個函式的參數說明如下：\n",
    "\n",
    "features: 特徵資料，這裡是計數向量表示的文本特徵。\n",
    "labels: 標籤資料，這裡是擅長工具的類別標籤。\n",
    "test_size: 測試集佔整個資料集的比例，這裡設定為 0.2，表示測試集佔總資料集的 20%。\n",
    "random_state: 隨機種子，用於確保每次執行程式時，切分的結果都是一致的。\n",
    "切分後，這個程式碼將訓練集的特徵資料指派給 X_train，訓練集的標籤資料指派給 y_train，測試集的特徵資料指派給 X_test，測試集的標籤資料指派給 y_test。\n",
    "\n",
    "這樣，我們就可以使用這些資料集來進行模型的訓練和評估，訓練集用於訓練模型的參數，測試集用於評估模型的性能。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "'''這兩段程式碼是用來初始化和訓練隨機森林分類器模型（Random Forest Classifier）。\n",
    "\n",
    "首先，RandomForestClassifier() 是 scikit-learn 中的一個機器學習模型類別，用於建立隨機森林分類器模型。在這裡，我們使用預設的參數來初始化模型，也可以根據需要進行參數的調整。\n",
    "\n",
    "然後，fit(X_train, y_train) 方法用於訓練模型，其中 X_train 是訓練集的特徵資料，y_train 是訓練集的標籤資料。透過這個方法，模型會從訓練集中學習特徵和標籤之間的關係，以便能夠對新的未見資料進行預測。\n",
    "\n",
    "訓練過程中，隨機森林模型會建立多個決策樹（Decision Tree），並進行集成學習。每棵決策樹會根據隨機選取的特徵子集和樣本子集進行訓練，以提高模型的泛化能力和抗過擬合性。\n",
    "\n",
    "在訓練完成後，模型就可以用於對新的測試資料進行預測，並根據預測結果進行分類任務。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Accuracy: 0.9313, Test Accuracy: 0.7817\n",
      "Epoch [2/10], Train Accuracy: 0.9313, Test Accuracy: 0.7738\n",
      "Epoch [3/10], Train Accuracy: 0.9313, Test Accuracy: 0.7817\n",
      "Epoch [4/10], Train Accuracy: 0.9313, Test Accuracy: 0.7817\n",
      "Epoch [5/10], Train Accuracy: 0.9313, Test Accuracy: 0.7897\n",
      "Epoch [6/10], Train Accuracy: 0.9313, Test Accuracy: 0.7698\n",
      "Epoch [7/10], Train Accuracy: 0.9313, Test Accuracy: 0.7857\n",
      "Epoch [8/10], Train Accuracy: 0.9313, Test Accuracy: 0.7817\n",
      "Epoch [9/10], Train Accuracy: 0.9313, Test Accuracy: 0.7817\n",
      "Epoch [10/10], Train Accuracy: 0.9313, Test Accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# 6. 初始化和訓練模型\n",
    "\n",
    "# 設定訓練的迭代次數和顯示進度的間隔\n",
    "num_epochs = 10\n",
    "display_interval = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.fit(X_train, y_train)\n",
    "    if (epoch + 1) % display_interval == 0:\n",
    "        # 計算訓練集和測試集的準確度\n",
    "        train_accuracy = model.score(X_train, y_train)\n",
    "        test_accuracy = model.score(X_test, y_test)\n",
    "        print(\"Epoch [{}/{}], Train Accuracy: {:.4f}, Test Accuracy: {:.4f}\".format(epoch+1, num_epochs, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''這段程式碼是用來進行模型的初始化和訓練，並在每個迭代周期（epoch）結束時顯示訓練集和測試集的準確度。\n",
    "\n",
    "首先，我們設定了訓練的迭代次數 num_epochs 和顯示進度的間隔 display_interval。在這個例子中，我們設定了10個迭代周期，並在每個週期結束時顯示準確度。\n",
    "\n",
    "接下來，使用 for 迴圈進行迭代，每個週期都調用 model.fit(X_train, y_train) 方法來訓練模型，其中 X_train 是訓練集的特徵資料，y_train 是訓練集的標籤資料。這樣模型在每個週期都會進行一次訓練，學習新的特徵和標籤關係。\n",
    "\n",
    "在每個週期結束時，我們使用 model.score(X_train, y_train) 和 model.score(X_test, y_test) 分別計算訓練集和測試集的準確度。這裡使用 score 方法來計算模型在資料集上的準確度，該方法會根據模型的預測結果和真實標籤進行比對。\n",
    "\n",
    "最後，使用 print 函式輸出訓練集和測試集的準確度，並使用格式化字串將週期數、迭代次數、訓練準確度和測試準確度輸出到終端。\n",
    "\n",
    "透過這段程式碼，我們可以觀察模型在每個週期結束時的訓練準確度和測試準確度的變化，以了解模型在訓練過程中的表現。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型準確率： 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# 6. 評估模型\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"模型準確率：\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測結果： ['Linux, Git, Python, MySQL', 'C, C++, Matlab, Python, R, MS SQL', 'C#,Python,MS SQL,HTML,JavaScript']\n",
      "相關值： [0.4495 0.4205 0.02  ]\n"
     ]
    }
   ],
   "source": [
    "# 8. 使用模型進行預測\n",
    "new_job_title = [\"資料科學家\"]  # 假設你有新的工作名稱需要預測擅長工具\n",
    "new_features = vectorizer.transform(new_job_title)\n",
    "predictions = model.predict(new_features)\n",
    "probabilities = model.predict_proba(new_features)\n",
    "\n",
    "# 取得前三筆預測結果及機率\n",
    "top_three_indices = np.argsort(probabilities[0])[::-1][:3]\n",
    "top_three_predictions = [model.classes_[idx] for idx in top_three_indices]\n",
    "top_three_probabilities = probabilities[0][top_three_indices]\n",
    "\n",
    "print(\"預測結果：\", top_three_predictions)\n",
    "print(\"相關值：\", top_three_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''這段程式碼用於使用已訓練好的模型進行預測。\n",
    "\n",
    "首先，我們提供了一個新的工作名稱 new_job_title，這是一個列表，假設其中只包含一個工作名稱 \"資料科學家\"。我們希望預測該工作所擅長的工具。\n",
    "\n",
    "接下來，使用 vectorizer.transform(new_job_title) 將新的工作名稱轉換成特徵表示，這裡使用之前初始化的 vectorizer 對新工作名稱進行轉換，得到 new_features。\n",
    "\n",
    "然後，使用 model.predict(new_features) 對新特徵進行預測，獲得預測結果 predictions。預測結果是模型對新工作名稱所擅長的工具進行預測的結果。\n",
    "\n",
    "同時，使用 model.predict_proba(new_features) 獲取預測的機率分佈，獲得 probabilities。機率分佈是模型對每個可能標籤的機率預測。\n",
    "\n",
    "接下來，我們希望取得前三個最有可能的標籤及其對應的機率。首先，使用 np.argsort(probabilities[0]) 對機率陣列進行排序，獲得排序後的索引位置。然後，使用 [::-1][:3] 取得排序後的前三個最大值的索引位置。這樣就獲得了前三個最有可能的標籤的索引位置。\n",
    "\n",
    "接著，使用 model.classes_[idx] 將這些索引位置轉換成實際的標籤值，並存儲在 top_three_predictions 中。\n",
    "\n",
    "同樣地，使用 probabilities[0][top_three_indices] 將這些索引位置對應的機率值提取出來，並存儲在 top_three_probabilities 中。\n",
    "\n",
    "最後，使用 print 函式輸出預測結果和相關值，並使用格式化字串將其輸出到終端。\n",
    "\n",
    "透過這段程式碼，我們可以將新的工作名稱提供給已訓練好的模型，並獲取模型對該工作所擅長的工具的預測結果及相關的機率值。'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
